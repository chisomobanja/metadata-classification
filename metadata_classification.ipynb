{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chisomobanja/metadata-classification/blob/main/metadata_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsEm1EomGRup"
      },
      "source": [
        "# 1. Business Understanding\n",
        "\n",
        "## 1.1 Problem statement\n",
        "Many articles published in UNZA journals have incomplete or inconsistent descriptive metadata (e.g., missing author names, publication dates, keywords, abstracts). This makes it difficult for researchers or librarians to correctly cite articles. We need a way to automatically classify the completeness of metadata associated with each article, so we can identify gaps and improve metadata quality.\n",
        "\n",
        "##1.2 Business Objectives\n",
        "\n",
        "\n",
        " 1. Automate Metadata Completeness Classification.\n",
        "\n",
        " 2. Diagnose Metadata Gaps Across UNZA journels.\n",
        "\n",
        " 3. improve Citation Accuracy and Research Discoverability.\n",
        "\n",
        " 4. Standaridise Metadata Practices.\n",
        "\n",
        " 5. Establish Sustainable Metadata Governance.\n",
        "\n",
        "\n",
        "### 1.2.1 What success might look like in real life :\n",
        "\n",
        "  - Metadata Completeness where each article recieves a scored ranging from 0% to 100% based on the presence of key metadata.\n",
        "\n",
        "  - Reduction in Incomplete Records where number of articles with missing metadata drops by a good percentage like 70%.\n",
        "\n",
        "\n",
        "- Improved Citation Quality where there is a great reduction in citation errors by researchers and librarians.\n",
        "\n",
        "- Metadata validation reduces manual correction workload by a great percentage.\n",
        "\n",
        "- Metadata audits and contributor training are institutionalised in various departments.\n",
        "\n",
        "## 1.3 Translating business objectives into data mining goals\n",
        "To achieve the above business objectives, our project will focus on developing a robust classification model capable of automatically evaluating the completeness of descriptive metadata for articles in UNZA journals. Specifically:\n",
        "- Build a supervised classification model that categorizes articles into defined completeness levels — for example:\n",
        "\n",
        "  -Complete (all required metadata fields present),\n",
        "\n",
        "  -Partially Complete (some key fields missing),\n",
        "\n",
        "  -Incomplete (major fields missing).\n",
        "- Train and validate the model using historical article metadata records, where completeness has been manually assessed, ensuring the model can generalize to new, unseen records.\n",
        "- Leverage appropriate features from metadata fields such as title, author(s), publication date, keywords, abstract, DOI, and journal name to determine the completeness score/class.\n",
        "- Enable metadata quality insights by aggregating classification results to identify common gaps across journals, which will guide targeted improvements and policy enforcement.\n",
        "- Set measurable model performance targets — e.g., at least 85% classification accuracy for predicting completeness categories on test data.\n",
        "\n",
        "## 1.4 Initial Project Success Criteria\n",
        "We’ll know our project is successful when we can clearly see improvements in both the quality of metadata and the ease of managing it. Specifically:\n",
        "\n",
        "1. ### Accurate classifications\n",
        "   Our model should correctly predict whether an article’s metadata is complete, partially complete, or incomplete at least 85% of the time. It should also be especially reliable in spotting incomplete records, with precision and recall above 80%.\n",
        "\n",
        "2. ### Trustworthy completeness scores\n",
        "   When we compare the system’s completeness scores to manual librarian checks, the difference should be very small ideally less than 5%.\n",
        "\n",
        "3. ### Noticeable improvement in records  \n",
        "   Within a period of time, the number of articles with missing or incomplete metadata should drop by at least half in the journals we focus on.\n",
        "\n",
        "4. ### Smooth workflow integration  \n",
        "   The tool should fit into the existing UNZA journal processes without slowing things down, allowing continuous checks without extra hassle.\n",
        "\n",
        "5. ### Positive user feedback  \n",
        "   Librarians, editors, and contributors should find the tool easy to use and report that it saves them time and reduces the amount of manual fixing they have to do.\n",
        "\n",
        "\n",
        "##1.5 Next Steps\n",
        "\n",
        "To move forward, we will begin by collecting and preparing metadata samples from existing UNZA journal articles. This includes labelling records for completeness and identifying key metadata fields. We will then design and test initial classification models, refining them based on performance metrics. Parallel to model development, we’ll engage stakeholders (librarians, editors, contributors) to ensure the solution aligns with their workflows and needs. Once validated, the tool will be piloted on select journals before broader deployment.\n",
        "\n",
        "# 2. Data Understanding\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Loading the dataset the dataset using the correct path\n",
        "var_dataset = pd.read_csv('/content/drive/.shortcut-targets-by-id/1BTuOqdVlsllIxOpwU9o5LGYwxkxuPLWL/misc-unza25-csc4792-project_team7/Metadata_classification_dataset - Sheet1.csv')\n",
        "\n",
        "print(\" Dataset loaded successfully!\")\n",
        "print(f\"Shape: {var_dataset.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKHxBoSJLJ_P",
        "outputId": "3cb969c7-d140-405d-fd30-646a127d1d63"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " Dataset loaded successfully!\n",
            "Shape: (259, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3XTEHHsuPVfD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_dataset.head()"
      ],
      "metadata": {
        "id": "qyhKqPobQPfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape: {var_dataset.shape}\")"
      ],
      "metadata": {
        "id": "Im7MjYhEPrWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"DATASET OVERVIEW \") #Checking the names of the columns\n",
        "print(f\"Dataset Shape: {var_dataset.shape}\")\n",
        "print(f\"Number of Rows: {var_dataset.shape[0]}\")\n",
        "print(f\"Number of Columns: {var_dataset.shape[1]}\")\n",
        "print(\"\\nColumn Names:\")\n",
        "for i, col in enumerate(var_dataset.columns, 1):\n",
        "    print(f\"{i}. {col}\")"
      ],
      "metadata": {
        "id": "s-NMStFqP156"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_dataset.info()"
      ],
      "metadata": {
        "id": "hdWUBjQJQGoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_dataset.describe(include='all') #Descriptive statistics"
      ],
      "metadata": {
        "id": "zrA_U0NWQ1YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"DATA QUALITY ANALYSIS\")\n",
        "print(\"\\n This is an analysis of missing values:\")\n",
        "\n",
        "missing_data = var_dataset.isnull().sum()\n",
        "missing_percentage = (missing_data / len(var_dataset)) * 100\n",
        "\n",
        "quality_df = pd.DataFrame({\n",
        "    'Column': var_dataset.columns,\n",
        "    'Missing_Count': missing_data.values,\n",
        "    'Missing_Percentage': missing_percentage.values\n",
        "}).sort_values('Missing_Percentage', ascending=False)\n",
        "\n",
        "print(quality_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "_qAA4X4VQ_bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset 259 academic articles with 11 columns including titles, abstracts, authors, and journal metadata. The missing data is mostly in the DOI's and Keywords with a few missing in 3 other categories. Other than that, the dataset does not have many many missing values."
      ],
      "metadata": {
        "id": "QZlY5jWRRu3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"This show a sample of the dataset giving out 10 randomly picked articles)\n",
        "\n"
      ],
      "metadata": {
        "id": "q7cTJq0ikoN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_dataset.inf0()"
      ],
      "metadata": {
        "id": "yvFKkx1FpJuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xf10pREMpVIK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}